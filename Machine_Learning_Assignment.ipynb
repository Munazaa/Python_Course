{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning <span style=\"color:green\">(Lecture_1)</span>\n",
    "- <span style=\"color:orange\">Machine learning types</span>\n",
    "- <span style=\"color:orange\">Algorithms used in each type</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is machine learning\n",
    "We can simply define that 'give training to a machine for a specific task and after training, it will be able to give prdictions on unseen related data smartly'. \n",
    "## Types of machine learning\n",
    "- <span style=\"color:green\">Supervised</span>\n",
    "- <span style=\"color:green\">Un-supervised/Clustering</span>\n",
    "- <span style=\"color:green\">Semi-supervised </span>\n",
    "- <span style=\"color:green\">Reinforcement</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised machine learning\n",
    "In this type, we have dataset with annonations (labels/masks) and we simply divide dataset in parts (training/testing). Most of the time 80% data is given to the machine for learning and 20% for the testing. After that, we analyse performance and take predictions on unseen dataset and make decision on results.\n",
    "## Algorithms for supervised ML\n",
    "-  Logistic regression\n",
    "-  K-neasrest Neighbors (K-NN)\n",
    "-  Support Vector Machine (SVM)\n",
    "-  Kernel SVM\n",
    "-  Naive Bayes\n",
    "-  Desision tree classification\n",
    "-  Random forest classification\n",
    "\n",
    "### Logistic regression\n",
    "Logistic regression used to predict the probability of a target variable. The nature of target or dependent variable would be only two possible classes (0 or 1, Yes or No, True or False) having binary target variables, but there can be two more categories of target variables that can be predicted by it. Based on those number of categories, Logistic regression can be divided into following types:\n",
    "- Binary or Binomial (depended variable has Two possible types)\n",
    "- Multinomial (depended variable has three or more possible un-ordered types e.g. (Type-A, Type-B, Type-C))\n",
    "- Ordinal (depended variable has three or more possible ordered type e.g. (good, very good, best))\n",
    "### K-NN\n",
    "K-nearest neighbors (KNN) algorithm is a type of supervised ML algorithm and is mainly used for classification predictive problems in industry. \n",
    "- Lazy learning algorithm: lazy learning (uses all the data for training while classification)\n",
    "- Non-parametric learning algorithm: a non-parametric learning (doesn’t assume anything about the underlying data)\n",
    "\n",
    "### SVM\n",
    "Support vector machines (SVMs) are powerful yet flexible supervised machine learning algorithms which are used both for classification. They are extremely popular because of their ability to handle multiple continuous and categorical variables. \n",
    "The main goal of SVM is to divide the datasets into classes to find a maximum marginal hyperplane (MMH) and it can be done in the following two steps −\n",
    "\n",
    "- First, SVM will generate hyperplanes (x-axis, y-axis) iteratively that segregates the classes in best way.\n",
    "\n",
    "- Then, it will choose the hyperplane that separates the classes correctly (margin line).\n",
    "\n",
    "### Kernel SVM\n",
    "SVM algorithms use a set of mathematical functions that are defined as the kernel. The function of kernel is to take data as input and transform it into the required form. Different SVM algorithms use different types of kernel functions. These functions can be different types.\n",
    "- linear\n",
    "- Non-linear\n",
    "- Polynomial\n",
    "- Radial basis function (RBF) \n",
    "- Sigmoid\n",
    "  \n",
    "### Naïve Bayes\n",
    "Naïve Bayes algorithms is a classification technique based on applying Bayes’ theorem with a strong assumption that all the predictors are independent to each other. Naïve Bayes classification algorithm can be used for binary as well as multi-class classification problems both.\n",
    "- Types of Naïve Bayes\n",
    "  - Gaussian Naïve Bayes (Gaussian distribution)\n",
    "  - Multinomial Naïve Bayes (Multinomial distributio)\n",
    "  - Bernoulli Naïve Bayes (binary (0s and 1s))\n",
    "\n",
    "### Desision tree classification\n",
    "Decision trees can be constructed by an algorithmic approach that can split the dataset in different ways based on different conditions. Decisions tress are the most powerful algorithms that falls under the category of supervised algorithms.\n",
    "- Classification decision trees (categorical)\n",
    "- Regression decision trees (continous data)\n",
    "The two main entities of a tree are decision nodes, where the data is split. And leaves, where we got outcome. The questions are decision nodes and final outcomes are leaves. \n",
    "\n",
    "### Random forest classification\n",
    "Random forest is a supervised learning algorithm which is used for both classification as well as regression. But however, it is mainly used for classification problems. Random forest algorithm creates decision trees on data samples and then gets the prediction from each of them and finally selects the best solution by means of voting. It is an ensemble method which is better than a single decision tree because it reduces the over-fitting by averaging the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-supervised/Clustering\n",
    "In this type, dataset has no information of annotations and machine has to be learn by itself. After drawing a reasonable pattern, it can give the predictions on the unseen dataset as well. \n",
    "## Algorithms\n",
    "- K-means clustering\n",
    "- Hierarchical clustering\n",
    "- Probabilistic clustering\n",
    "  \n",
    "### K-means clustering\n",
    "K-means clustering algorithm computes the centroids and iterates until we it finds optimal centroid. It assumes that the number of clusters are already known. It is also called flat clustering algorithm. The number of clusters identified from data by algorithm is represented by ‘K’ in K-means. \n",
    "K-means follows Expectation-Maximization approach to solve the problem. The Expectation-step is used for assigning the data points to the closest cluster and the Maximization-step is used for computing the centroid of each cluster.\n",
    "\n",
    "### Hierarchical clustering\n",
    "Hierarchical clustering is another unsupervised learning algorithm that is used to group together the unlabeled data points having similar characteristics. Hierarchical clustering algorithms falls into following two categories:\n",
    "- Agglomerative hierarchical algorithms (each data point is treated as a single cluster)\n",
    "- Divisive hierarchical algorithms (all the data points are treated as one big cluster)\n",
    "\n",
    "### Probabilistic clustering\n",
    "In machine learning, a probabilistic classifier is a classifier that is able to predict, given an observation of an input, a probability distribution over a set of classes, rather than only outputting the most likely class that the observation should belong to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised \n",
    "In this type, we have dataset which is not fully annonated, or we can say some data has labels information and some has missing information. So we can try or mix both supervised and un-supervised approaches to solve such problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement\n",
    "This one is advance type and it is hit & trial based learning of the machine. Basically, it learns from the mistakes and as we give and guide the machine about its performance, it learns and find a suitable pattern for our dataset.Reinforcement learning is all about learning from the environment through interactions.For example, initially, the baby can’t walk so you support the baby as much as you can, but you can’t be there all the time so the baby has to learn it by itself. You can’t teach the baby fully supervised, cause we know many things fall in the process. so the baby has to learn it from experience <span style=\"color:red\">(*trial and fail*)</span>.\n",
    "## Algorithms\n",
    "- Model-Free reinforcement learning\n",
    "    - Policy optimization\n",
    "    - Q- Learning\n",
    "- Model based reinforcement learning\n",
    "    - Learn the model\n",
    "    - Given the model\n",
    "  \n",
    "### Model-Free reinforcement learning \n",
    "The model stands for the simulation of the dynamics of the environment. It predicts what the environment will give next. Model-free algorithms rely on trial-and-error to update its knowledge. As a result, it does not require space to store all the combination of states and actions. Policy optimization and Q-Learning are examples of model-free learning algorithm.\n",
    "- Policy optimization: You can think of policy as a strategy or agent’s behavior function. Finding the optimal policy / optimal value functions is the key for solving reinforcement learning problems. The optimal policy is the policy which maximizes the expected reward for each state.\n",
    "- Q-learning: Off policy learning method , means, it uses the target policy to choose the best next action  while following the behavior policy.\n",
    "\n",
    "### Model based reinforcement learning\n",
    "Model-based algorithms have been shown to provide more sample efficient and generalizable learning. In model-based deep reinforcement learning, a neural network learns a dynamics model, which predicts the feature values in the next state of the environment, and possibly the associated reward, given the current state and action. This dynamics model can then be used to simulate experiences, reducing the need to interact with the real environment whenever a new task has to be learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [RL](https://gibberblot.github.io/rl-notes/single-agent/model-free.html)\n",
    "\n",
    "- [Wiki](https://en.wikipedia.org/wiki/Probabilistic_classification#:~:text=In%20machine%20learning%2C%20a%20probabilistic%20classifier%20is%20a,likely%20class%20that%20the%20observation%20should%20belong%20to)\n",
    "\n",
    "- [Deep Math](https://medium.com/deep-math-machine-learning-ai/ch-12-1-model-free-reinforcement-learning-algorithms-monte-carlo-sarsa-q-learning-65267cb8d1b4)\n",
    "\n",
    "- [Model RL](https://github.com/ThGravo/ModelRL#:~:text=In%20model-based%20deep%20reinforcement%20learning%2C%20a%20neural%20network,associated%20reward%2C%20given%20the%20current%20state%20and%20action.)\n",
    "\n",
    "- [Tutorialspoint](https://www.tutorialspoint.com/machine_learning_with_python/classification_algorithms_random_forest.htm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
